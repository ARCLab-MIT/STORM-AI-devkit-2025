# Office Hours
Office hours are held weekly on Wednesdays from 11:00 am to 11:30 am EST. Participants may ask general questions about the challenge (i.e. regarding data, submissions, evaluation, etc.), but all questions about specific approaches should be posted to the forums instead. Transcripts of the weekly office hours will be provided in the next section as they become available.
<div style="display: flex; justify-content: left; align-items: center; gap: 10px; padding: 10px;">
  <div style="display: inline-flex; align-items: center; background-color: #4d4d4d; color: #ffffff; border-radius: 5px; padding: 5px 10px; font-family: Arial, sans-serif; font-size: 14px; text-align: center;">
    <img src="https://github.com/user-attachments/assets/22255638-84ce-4f79-a4e9-7e51d517c428" alt="Codabench Logo" style="height: 20px; margin-right: 8px;">
    <a href="https://mit.zoom.us/j/92427066103" target="_blank" style="color: #ffffff; text-decoration: none;">
        Office Hours
      </a>
  </div>
</div>

## Transcripts
<div class="faq-container" style="font-family: Arial, sans-serif;">
  <details style="margin-bottom: 10px; border: 1px solid #e0e0e0; border-radius: 5px; padding: 10px;">
    <summary style="font-size: 16px; font-weight: bold; cursor: pointer; color: #2b2b2b;">
      February 12, 2025
    </summary>
    <p style="margin-top: 10px; font-size: 14px; color: #555;">No transcript available</p>
  </details>

  <details style="margin-bottom: 10px; border: 1px solid #e0e0e0; border-radius: 5px; padding: 10px;">
    <summary style="font-size: 16px; font-weight: bold; cursor: pointer; color: #2b2b2b;">
      February 19, 2025
    </summary>
    <p style="margin-top: 10px; font-size: 14px; color: #555;">[Organizer 1] 17:04:42<br>
      Okay, I think we can get started. If everyone has any questions, feel free to ask.<br>
      [Participant 1] 17:05:31<br>
      I have a question regarding the libraries. Are we allowed to use any of the libraries or there are the limitations that we have to use certain libraries for this project?<br>
      [Participant 1] 17:05:43<br>
      Because the libraries was not mentioned in the GitHub repository or anywhere from where the data sources was being downloaded.<br>
      [Organizer 2] 17:05:57<br>
      I… Yeah, I think that as long as you as you provide the libraries that you are using in the environment demo file is not going to be any kind of probably with that.<br>
      [Organizer 1] 17:05:57<br>
      Go on a second.<br>
      [Organizer 2] 17:06:26<br>
      But keep in mind that you have to that the libraries that you use have to be like Micro Konda, Micromambamba.<br>
      [Participant 1] 17:06:26<br>
      Thank you.<br>
      [Organizer 2] 17:06:37<br>
      Is able to install on their dependencies dependencies that do need to run your script so check that before submitting anything?<br>
      [Organizer 2] 17:06:49<br>
      With all that said, you won't have any kind of trouble.<br>
      [Participant 1] 17:06:54<br>
      Sure, sure.<br>
      [Organizer 2] 17:06:58<br>
      You're welcome.<br>
      [Participant 1] 17:11:56<br>
      This submission for this project is being postponed to 21st April, right?<br>
      [Organizer 2] 17:12:03<br>
      Yeah, yesterday, I think that yesterday it was yesterday when we announced that we are moving the deadline to The 21st, yeah.<br>
      [Organizer 2] 17:12:20<br>
      And also you should have 10 extra submissions so don't worry on going over in the submission process.<br>
      [Organizer 2] 17:12:31<br>
      Because we gave you a little bit more submission.<br>
      [Organizer 1] 17:12:42<br>
      Hello, Participant 3. So you just joined the call if you have any question we'll just feel free to ask any question. We're just waiting for new participant if they need any help.<br>
      [Participant 2] 17:12:55<br>
      I actually had one question. As I was like processing the density data, I think this was asked in the forum. I don't recall what the answer was. Maybe it was already resolved.<br>
      [Participant 2] 17:13:05<br>
      But some of the density data has like values of like like 9e to the 32. Is this like supposed to be treated as like noise or Or like the true, I mean, obviously it's not the true value because it seems to be like a non-trending value.<br>
      [Participant 2] 17:13:26<br>
      Are we supposed to handle these by like throwing these density data away or Yeah, how would we like handle those like particular rows?<br>
      [Organizer 2] 17:13:36<br>
      Yeah, exactly. Those are like Python, float 32 infinite values So yeah, you have to discard all of them.<br>
      [Participant 2] 17:13:48<br>
      Okay, sounds good.<br>
      [Organizer 2] 17:13:51<br>
      Also, it could be some values that are over CETO, like, I don't know.<br>
      [Organizer 2] 17:14:00<br>
      1 to a power of 20 or something like that, you also have to discard the those So we only have values, real values are just the only one that are under 10 to the minus 7.<br>
      [Participant 2] 17:14:17<br>
      I see. So we should, anything above 10 to the negative 7.<br>
      [Participant 2] 17:14:22<br>
      We should throw away essentially in the density data.<br>
      [Organizer 2] 17:14:25<br>
      Yeah, that's it.<br>
      [Participant 3] 17:14:31<br>
      I just got a couple questions here. About the submissions.<br>
      [Participant 3] 17:14:38<br>
      The first one, I'm guessing for the 80 submission limit is per team, not per a person.<br>
      [Organizer 2] 17:14:47<br>
      Yeah, it's per team.<br>
      [Participant 3] 17:14:49<br>
      Per team okay um Another question is, did you guys So we had a submission. Did you guys like rerun them? Because we had one and then it seemed like another one came through and we got a different score.<br>
      [Participant 3] 17:14:59<br>
      So I was wondering if you guys would be<br>
      [Organizer 2] 17:15:03<br>
      Yeah, we will run maybe you have one that has a perfect score Like one.<br>
      [Participant 3] 17:15:08<br>
      Yeah, yeah, yeah. That's what happened, yeah.<br>
      [Organizer 2] 17:15:11<br>
      Yeah, we have some errors in the scoring file. So we have to rerun it.<br>
      [Participant 3] 17:15:16<br>
      Okay, so you guys, so now… Okay, so you re-ran them and now that's the correct score now is what's in there.<br>
      [Organizer 2] 17:15:25<br>
      Yeah. That's correct.<br>
      [Participant 3] 17:15:26<br>
      Okay. And then let me just clarify with the ghost data. I think I saw in the discussion that you guys are going to go back through and add some of the missing files.<br>
      [Organizer 3] 17:15:40<br>
      Yeah, the way that that works is there are multiple satellites and we were just missing data from a couple of them that covered the time frame that's missing.<br>
      [Organizer 3] 17:15:49<br>
      And we were not aware of that. Until somebody pointed it out. So we're just going to go back through and we'll process that data from the satellites that we initially didn't have.<br>
      [Participant 3] 17:16:00<br>
      Okay. I need to just throw it in that Dropbox, same Dropbox.<br>
      [Organizer 3] 17:16:03<br>
      Yep. And we will send out an email whenever that goes up.<br>
      [Participant 3] 17:16:07<br>
      Okay. And then, yeah, I think that's… I think that's all I had. Thank you.<br>
      [Organizer 2] 17:16:20<br>
      In any case, we try to keep the wiki app like updated So if you are looking into the different versions of the wiki, you could see if we made any change So try to use the wiki as your guidance.<br>
      [Participant 2] 17:25:14<br>
      Hello. Yes, since someone's asking a question, if I could maybe ask maybe a little more obvious question, just like more of a confirmation It seems like the performance metrics or the scoring is based on the MSIS baseline I'm assuming that means that you guys are taking the initial state and then<br>
      [Participant 2] 17:25:37<br>
      Using the propagation. With the MSIS model at the locations of the propagator's states and then using that to compare against the true densities provided by the the spacecraft data sets that you provided.<br>
      [Participant 2] 17:25:53<br>
      Is that the case where that's what you're comparing? They're using the MSS to in line with the density inputs for the propagator<br>
      [Organizer 2] 17:26:13<br>
      Yeah, well, what we do is that we… Yes, introduce to the proprietor the MCIS model.<br>
      [Organizer 2] 17:26:22<br>
      We give to it the initial state and just retrieve the density values.<br>
      [Organizer 2] 17:26:28<br>
      And then we apply our rolling mean to get the orbital mean the orbital mean values.<br>
      [Organizer 2] 17:26:37<br>
      And to do so, to establish the window size we use the mean motion so we have we know more or less what is the orbital And… the orbit video.<br>
      [Organizer 2] 17:26:56<br>
      So that is how are we… scoring the MCs this slide.<br>
      [Participant 2] 17:27:03<br>
      Got it. And for the density predictions.<br>
      [Participant 2] 17:27:10<br>
      Well, obviously, I'm using… like the data set itself for like train test splitting But when the scoring is done, I'm assuming those like large values we mentioned, like the E, Any values above e to the negative 7.<br>
      [Participant 2] 17:27:27<br>
      When the predictions are being generated from the model. They're going to generate predictions for those indices and maybe on your evaluation, you'll have those metrics and then the errors will be compared to that metric.<br>
      [Participant 2] 17:27:43<br>
      Will you guys be throwing it away on your side as well for the prediction or for the estimation?<br>
      [Participant 2] 17:27:47<br>
      Or rather for the… For the scoring or should we like, what should we put in those indices where those predictions occur.<br>
      [Participant 2] 17:27:58<br>
      For comparison, should we put like zero or… put that in.<br>
      [Organizer 2] 17:28:01<br>
      Well you usually… Usually you are using machine learning models for other kinds of models.<br>
      [Organizer 2] 17:28:09<br>
      If you substitute those values with the number values with nons.<br>
      [Organizer 2] 17:28:15<br>
      It will work just fine. But what we do is to when we are going to score we apply as the threshold that you mentioned, 10 to the minus 7.<br>
      [Organizer 2] 17:28:28<br>
      On all the values that are over that scope, we are not taking into account in the scoring process.<br>
      [Participant 2] 17:28:36<br>
      Got it. Okay. Sounds good. So I'll kind of replicate that. I think like having… the scoring done on like a small like similar score to kind of evaluate how well the predictions are happening on my side before submitting would be helpful.<br>
      [Participant 2] 17:28:55<br>
      So I guess I will do the same approach. Yeah, thank you.<br>
      [Organizer 2] 17:28:59<br>
      Okay, great. Also, if you want the scoring script, you have it in the in the development kit of the challenge.<br>
      [Participant 2] 17:29:09<br>
      All right. Okay, I'll take a look at that too.<br>
      [Organizer 2] 17:29:14<br>
      Yeah, you can find it in the baseline directory as evaluation.py<br>
      [Participant 2] 17:29:22<br>
      Okay, sweet. Yeah, I haven't gotten that to that point yet, but I'll definitely check that out. That would save me a lot of time.<br>
      [Participant 2] 17:29:28<br>
      Thank you. Awesome. Take care.<br>
      [Organizer 2] 17:29:29<br>
      Sweet. You're welcome.<br>
      </p>
  </details>
</div>
